{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "K8aJgp1ynSTo",
        "yHXFZy0lFKBU"
      ],
      "authorship_tag": "ABX9TyMi+jKAIEekFvGwkYN1AyTi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabricecordelieres/Colab-FRAP_Script/blob/main/FRAP_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FRAP Analysis**\n",
        "\n",
        "---\n",
        "## **Data organization**\n",
        "This notebook takes as an input a single zip file containing several excel files generating using an ImageJ data extraction toolset (one file per dataset). Each Xls file is expected to contain one columns per analyzed ROI where values corresponds to the following normalization of fluorescence:\n",
        "* \"MM_Roi_XX\": Double normalized fluorescence for ROI_XX.\n",
        "* \"Full_Scale_MM_Roi_XX\": Full scale, double normalized fluorescence for ROI_XX.\n",
        "* \"Time_sec\": Extracted timestamp.\n",
        "\n",
        "Additionnal columns may appear but won't be taken care of.\n",
        "\n",
        "---\n",
        "## **How to run this script**\n",
        "\n",
        "1.   Have all you data ready: the toolset should have generated a **\"_dataToUpload.zip\"** file in the output folder: locate it and get ready to select it when asked.\n",
        "2.   Run each step: press the play button, on the left side of the relevent cells\n",
        "  1. **Step 1** is non interactive: point at the \\[   \\] mark. It will change to a play button. Press play and wait for a green tick mark to appear on the left.\n",
        "  2. **Step 2** is interactive: if applicable, unfold the cell and point at the \\[   \\] mark. It will change to a play button. Press play: a **\"Select file\"** button should appear below the cell. Use it to navigate your drive and locate the zip file. The selected file will be uploaded to the swap space of the Google Colab environment, will be unzip.\n",
        "  3. **Step 3** is non interactive: point at the \\[   \\] mark. It will change to a play button. Press play and wait for a green tick mark to appear on the left.  During this step, data compilation will occur. The resulting files will be zipped and directly downloaded to your computer.\n",
        "\n"
      ],
      "metadata": {
        "id": "Enj8xP2aJ4Gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Prepare the environment for execution\n",
        "_Simply execute the two following cells either in one row or individually_"
      ],
      "metadata": {
        "id": "K8aJgp1ynSTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Step 1.1: Import librairies\n",
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.optimize import fsolve\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import zipfile\n",
        "import shutil\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "rQNDHOaBJzyq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Step 1.2: Define procedures on how to deal with data\n",
        "\n",
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "def list_xls_files(directory):\n",
        "  \"\"\"Lists all XLS files in a given directory.\n",
        "\n",
        "  Args:\n",
        "    directory: The directory to search for XLS files.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings, where each string is the full path to an XLS file.\n",
        "  \"\"\"\n",
        "  xls_files = []\n",
        "  for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".xls\") or filename.endswith(\".xlsx\"):\n",
        "      xls_files.append(os.path.join(directory, filename))\n",
        "  return xls_files\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# Define the single exponential function\n",
        "def single_exponential_func(x, I0, a, b):\n",
        "  '''Single exponential function\n",
        "\n",
        "  Args:\n",
        "    x: x value\n",
        "    I0: I0 value\n",
        "    a: a value\n",
        "    b: b value\n",
        "\n",
        "  Returns:\n",
        "    I0-a*exp(-b*x)\n",
        "  '''\n",
        "  return I0 - a * np.exp(-b * x)\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# Define the double exponential function\n",
        "def double_exponential_func(x, I0, a, b, c, d):\n",
        "  '''Double exponential function\n",
        "\n",
        "  Args:\n",
        "    x: x value\n",
        "    I0: I0 value\n",
        "    a: a value\n",
        "    b: b value\n",
        "    c: c value\n",
        "    d: d value\n",
        "\n",
        "  Returns:\n",
        "    I0-a*exp(-b*x)-c*exp(-d*x)\n",
        "  '''\n",
        "  return I0 - a * np.exp(-b * x) - c * np.exp(-d * x)\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# Define goodness of fitting\n",
        "def goodness_of_fit(y_data, fitted_y):\n",
        "  '''Computes goodness of fit using R-squared\n",
        "  Args:\n",
        "    y_data: original data\n",
        "    fitted_y: fitted data\n",
        "\n",
        "  Returns:\n",
        "    R-squared value\n",
        "  '''\n",
        "  ss_res = np.sum((y_data - fitted_y) ** 2)\n",
        "  ss_tot = np.sum((y_data - np.mean(y_data)) ** 2)\n",
        "  r_squared = 1 - (ss_res / ss_tot)\n",
        "  return r_squared\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "def find_x_at_half_max_double_exponential(x_data, I0, a, b, c, d):\n",
        "    \"\"\"\n",
        "    Finds the x-value where the double exponential function is at half its maximum.\n",
        "\n",
        "    Args:\n",
        "        x_data: Array of x-values.\n",
        "        I0, a, b, c, d: Parameters of the double exponential function.\n",
        "\n",
        "    Returns:\n",
        "        The x-value at half maximum, or None if no solution is found.\n",
        "    \"\"\"\n",
        "\n",
        "    y_max = I0\n",
        "    half_max = y_max / 2\n",
        "\n",
        "    # Define the function to solve for the root (where f(x) - half_max = 0)\n",
        "    def equation_to_solve(x):\n",
        "        return double_exponential_func(x, I0, a, b, c, d) - half_max\n",
        "\n",
        "    # Initial guess for x (you might need to adjust this based on your data)\n",
        "    initial_guess = x_data[np.argmin(np.abs(double_exponential_func(x_data, I0, a, b, c, d)-half_max))]\n",
        "\n",
        "    try:\n",
        "      x_half_max = fsolve(equation_to_solve, initial_guess)[0]\n",
        "      return x_half_max\n",
        "    except RuntimeError:\n",
        "      print(\"Error - fsolve failed to find a solution\")\n",
        "      return None\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "def fit_dataset_exponential(dataset_dir, dataset_name, is_single):\n",
        "  '''\n",
        "\n",
        "  Args:\n",
        "    dataset_dir: The directory containing the dataset.\n",
        "    dataset_name: The name of the dataset.\n",
        "    is_single: True if the fit should be performed based on a single exponential, otherwise will be performed on a double exponential.\n",
        "\n",
        "  Returns:\n",
        "    out_path: The path to the output directory.\n",
        "\n",
        "  '''\n",
        "  # Set fitting type attribute\n",
        "  fitting_type=\"_single-exponential\" if is_single else \"_double-exponential\"\n",
        "  fitting_type_legend=\"Single Exponential\" if is_single else \"Double Exponential\"\n",
        "\n",
        "  # Defines basename\n",
        "  basename=dataset_name.replace('_Quantif_Norm.xls', '')\n",
        "\n",
        "   # Open file\n",
        "  df = pd.read_csv(os.path.join(dataset_dir, dataset_name), sep='\\t')\n",
        "\n",
        "  # Create output dir\n",
        "  out_path=os.path.join(dataset_dir, basename)\n",
        "  if not os.path.exists(out_path):\n",
        "    os.mkdir(out_path)\n",
        "\n",
        "  # Select columns starting with \"Time_sec\" or \"Full_Scale\"\n",
        "  selected_columns = [col for col in df.columns if col.startswith('Time_sec') or col.startswith('MM_') or col.startswith('Full_Scale')]\n",
        "  new_df = df[selected_columns]\n",
        "\n",
        "  # Create lists to store fitted data and parameters\n",
        "  fitted_data = []\n",
        "  fitting_parameters = []\n",
        "  columns_names=['Time_sec']\n",
        "\n",
        "  with PdfPages(os.path.join(out_path, basename+fitting_type+'_plots.pdf')) as pdf:\n",
        "      for col in [col for col in new_df.columns if  col.startswith('MM_') or col.startswith('Full_Scale')]:\n",
        "          # Find the index of the largest drop\n",
        "          data = new_df[col].values\n",
        "          drop_indices = np.where(np.diff(data) < -50)[0]\n",
        "          if len(drop_indices) > 0:\n",
        "              max_drop_index = drop_indices[0]\n",
        "              x_data = new_df['Time_sec'][max_drop_index:]\n",
        "              y_data = new_df[col][max_drop_index:]\n",
        "\n",
        "              try:\n",
        "\n",
        "                  if(is_single):\n",
        "                    params, covariance = curve_fit(single_exponential_func, x_data, y_data, p0=[100, 90, 0.015])\n",
        "                    I0, a, b = params\n",
        "                    fitted_y = single_exponential_func(x_data, I0, a, b)\n",
        "                    #Extracted parameters\n",
        "                    t_half=np.log(2)/b\n",
        "                    mobile_fraction=100*a/(100-(I0-a)) # Used 100 instead of 1 cf normalisation between [0; 100] and not [0; 1]\n",
        "                  else:\n",
        "                    params, covariance = curve_fit(double_exponential_func, x_data, y_data, p0=[100, 60, 0.01, 30, 0.02])\n",
        "                    I0, a, b, c, d = params\n",
        "                    fitted_y = double_exponential_func(x_data, I0, a, b, c, d)\n",
        "                    #Extracted parameters\n",
        "                    t_half=find_x_at_half_max_double_exponential(x_data, I0, a, b, c, d)#find_x_at_half_max(x_data.to_numpy, fitted_y.to_numpy, I0)\n",
        "                    mobile_fraction=100*(a+c)/(100-(I0-a-c)) # Used 100 instead of 1 cf normalisation between [0; 100] and not [0; 1]\n",
        "\n",
        "                  # Get goodness of fitting\n",
        "                  r_squared = goodness_of_fit(y_data, fitted_y)\n",
        "\n",
        "\n",
        "\n",
        "                  columns_names.append(col)\n",
        "                  fitted_data.append(fitted_y)\n",
        "\n",
        "                  if(is_single):\n",
        "                    fitting_parameters.append([col, I0, a, b, r_squared, t_half, mobile_fraction])\n",
        "                  else:\n",
        "                    fitting_parameters.append([col, I0, a, b, c, d, r_squared, t_half, mobile_fraction])\n",
        "\n",
        "                  plt.figure(figsize=(10, 6))\n",
        "                  plt.plot(x_data, y_data, label='Data')\n",
        "                  plt.plot(x_data, fitted_y, label=fitting_type_legend+' Fit', color='red')\n",
        "                  plt.xlabel('Time_sec')\n",
        "                  plt.ylabel(col)\n",
        "                  plt.title(f'{col} vs. Time_sec ('+fitting_type_legend+' Fit)')\n",
        "                  plt.text(0.05, 0.95, f\"R-squared: {r_squared:.4f}\", transform=plt.gca().transAxes) #Display R-squared on the plot\n",
        "                  plt.legend()\n",
        "                  plt.grid(True)\n",
        "                  pdf.savefig()\n",
        "                  plt.close()\n",
        "\n",
        "              except RuntimeError:\n",
        "                  print(f\"Error - curve_fit failed for {col}\")\n",
        "                  fitting_parameters.append([col, \"Error\", \"Error\", \"Error\", \"Error\", np.nan, np.nan])\n",
        "          else:\n",
        "              print(f\"No significant drop found for {col}\")\n",
        "              fitting_parameters.append([col, \"No drop\", \"No drop\", \"No drop\", \"No drop\", np.nan, np.nan])\n",
        "\n",
        "  # Create and save Excel files\n",
        "  fitted_data_df = pd.DataFrame(fitted_data).T\n",
        "  fitted_data_df.insert(0, 't', new_df['Time_sec'])\n",
        "  fitted_data_df.columns = columns_names\n",
        "  fitted_data_df.to_excel(os.path.join(out_path, basename+fitting_type+'_fitted_values.xlsx'), index=False)\n",
        "\n",
        "  if(is_single):\n",
        "    fitting_parameters_df = pd.DataFrame(fitting_parameters, columns=['ROI', 'I0', 'a', 'b', 'R2', 't_half', 'mobile_fraction'])\n",
        "  else:\n",
        "    fitting_parameters_df = pd.DataFrame(fitting_parameters, columns=['ROI', 'I0', 'a', 'b', 'c', 'd', 'R2', 't_half', 'mobile_fraction'])\n",
        "\n",
        "  fitting_parameters_df.to_excel(os.path.join(out_path, basename+fitting_type+'_fitting_parameters.xlsx'), index=False)\n",
        "\n",
        "  return out_path\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "def unzip_file(zip_filepath, extract_dir):\n",
        "  \"\"\"Unzips a zip file to a specified directory.\n",
        "\n",
        "  Args:\n",
        "    zip_filepath: The path to the zip file.\n",
        "    extract_dir: The directory to extract the contents to.\n",
        "  \"\"\"\n",
        "  with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "def create_zip_from_folders(folder_list, zip_filename, remove_folder):\n",
        "  \"\"\"Creates a zip archive containing all folders from a given list.\n",
        "\n",
        "  Args:\n",
        "    folder_list: A list of folder paths to include in the zip archive.\n",
        "    zip_filename: The name of the output zip file.\n",
        "    remove_folder: True to erase the original folders after zipping.\n",
        "  \"\"\"\n",
        "  with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for folder in folder_list:\n",
        "      for root, _, files in os.walk(folder):\n",
        "        for file in files:\n",
        "          zipf.write(os.path.join(root, file),\n",
        "                     os.path.relpath(os.path.join(root, file),\n",
        "                                     os.path.join(folder, '..')))\n",
        "  if remove_folder:\n",
        "    for folder in folder_list:\n",
        "      shutil.rmtree(folder)\n",
        "\n"
      ],
      "metadata": {
        "id": "WuPksS0p8UFr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Upload data\n",
        "_Simply execute the following cell, then select the file to upload_\n",
        "\n",
        "**NB:** This cell should be unfolded in order to see the file selection box !"
      ],
      "metadata": {
        "id": "45GNwQJGFBbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a dialog box to allow uploading the data\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "lFGhNvAbinLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Process data\n",
        "_Simply execute the following cell: once processing has been performed, the output file should automatically be downloaded to your computer_\n"
      ],
      "metadata": {
        "id": "yHXFZy0lFKBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the name of the (first) uploaded file\n",
        "uploaded_file=next(iter((uploaded)))\n",
        "\n",
        "# Build the full paths for uploaded and unzipped data\n",
        "uploaded_file_path=os.path.join('/content/', uploaded_file)\n",
        "unzip_folder=os.path.join('/content/', uploaded_file.replace('.zip', '/'))\n",
        "\n",
        "# Unzip the first file into the content folder\n",
        "unzip_file(uploaded_file_path, unzip_folder)\n",
        "\n",
        "# Remove uploaded file\n",
        "os.remove(uploaded_file)\n",
        "\n",
        "# Get the list of all the XLS files\n",
        "list_xls=list_xls_files(unzip_folder)\n",
        "created_folders=[]\n",
        "\n",
        "# Analyze data\n",
        "for xls in tqdm(list_xls, desc=\"Processing file\"):\n",
        "  tqdm.write(f\"Processing file: {os.path.basename(xls)}\")\n",
        "  created_folders.append(fit_dataset_exponential(unzip_folder, os.path.basename(xls), True))\n",
        "  fit_dataset_exponential(unzip_folder, os.path.basename(xls), False)\n",
        "\n",
        "# Zip the data\n",
        "create_zip_from_folders(created_folders, 'Fitted_data.zip', True)\n",
        "\n",
        "# Remove the data, once zipped\n",
        "shutil.rmtree(unzip_folder)\n",
        "\n",
        "# Automatically download the file\n",
        "files.download('Fitted_data.zip')"
      ],
      "metadata": {
        "id": "YHXeJ6GYNijm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MN1zkTiDFUml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: What's in the output ?\n",
        "\n",
        "Once the script has finished processing the data, all outputs will be automatically zipped (Fitted_data.zip) and downloaded. It contains one folder per input dataset, named after the dataset. Each folder contains the following files:\n",
        "- **DATASET-NAME_single-exponential_plots.pdf:** for data where fitting against a single exponential was possible, displays one page per ROI, overlaying as a graph the fitted data to the original data.\n",
        "- **DATASET-NAME_single-exponential_fitted_values.xlsx:** for double normalized and full scale data, displays the modelized the values (when fitting a single exponential was possible).\n",
        "- **DATASET-NAME_single-exponential_fitting_parameters.xlsx:** for double normalized and full scale data, displays the parameters for the single exponential model, a goodness of fitting value and estimation of both the t_half and mobile fraction (when fitting was possible).\n",
        "- **DATASET-NAME_double-exponential_plots.pdf:** for data where fitting against a double exponential was possible, displays one page per ROI, overlaying as a graph the fitted data to the original data.\n",
        "- **DATASET-NAME_double-exponential_fitted_values.xlsx:** for double normalized and full scale data, displays the modelized the values (when fitting a double exponential was possible)."
      ],
      "metadata": {
        "id": "uX1P_khYFVSf"
      }
    }
  ]
}