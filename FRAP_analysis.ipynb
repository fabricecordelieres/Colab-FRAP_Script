{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "K8aJgp1ynSTo",
        "yHXFZy0lFKBU"
      ],
      "authorship_tag": "ABX9TyO+yn15IQHBXF8JUsaeXXRm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabricecordelieres/Colab-FRAP_Script/blob/main/FRAP_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FRAP Analysis**\n",
        "\n",
        "---\n",
        "## **Data organization**\n",
        "This notebook takes as an input a single zip file containing several excel files generating using an ImageJ data extraction toolset (one file per dataset). Each Xls file is expected to contain one columns per analyzed ROI where values corresponds to the following normalization of fluorescence:\n",
        "* \"MM_Roi_XX\": Double normalized fluorescence for ROI_XX.\n",
        "* \"Full_Scale_MM_Roi_XX\": Full scale, double normalized fluorescence for ROI_XX.\n",
        "* \"Time_sec\": Extracted timestamp.\n",
        "\n",
        "Additionnal columns may appear but won't be taken care of.\n",
        "\n",
        "---\n",
        "## **How to run this script**\n",
        "\n",
        "1.   Have all you data ready: the toolset should have generated a **\"_dataToUpload.zip\"** file in the output folder: locate it and get ready to select it when asked.\n",
        "2.   Run each step: press the play button, on the left side of the relevent cells\n",
        "  1. **Step 1** is non interactive: point at the \\[   \\] mark. It will change to a play button. Press play and wait for a green tick mark to appear on the left.\n",
        "  2. **Step 2** is interactive: if applicable, unfold the cell and point at the \\[   \\] mark. It will change to a play button. Press play: a **\"Select file\"** button should appear below the cell. Use it to navigate your drive and locate the zip file. The selected file will be uploaded to the swap space of the Google Colab environment, will be unzip.\n",
        "  3. **Step 3** is non interactive: point at the \\[   \\] mark. It will change to a play button. Press play and wait for a green tick mark to appear on the left.  During this step, data compilation will occur. The resulting files will be zipped and directly downloaded to your computer.\n",
        "\n"
      ],
      "metadata": {
        "id": "Enj8xP2aJ4Gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Prepare the environment for execution\n",
        "_Simply execute the two following cells either in one row or individually_"
      ],
      "metadata": {
        "id": "K8aJgp1ynSTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Step 1.1: Import librairies\n",
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.optimize import fsolve\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import zipfile\n",
        "import shutil\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "rQNDHOaBJzyq",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Step 1.2: Define procedures on how to deal with data\n",
        "\n",
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "def list_xls_files(directory):\n",
        "  \"\"\"Lists all XLS files in a given directory.\n",
        "\n",
        "  Args:\n",
        "    directory: The directory to search for XLS files.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings, where each string is the full path to an XLS file.\n",
        "  \"\"\"\n",
        "  xls_files = []\n",
        "  for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".xls\") or filename.endswith(\".xlsx\"):\n",
        "      xls_files.append(os.path.join(directory, filename))\n",
        "  return xls_files\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# Define the single exponential function\n",
        "def single_exponential_func(x, I0, a, b):\n",
        "  '''Single exponential function\n",
        "\n",
        "  Args:\n",
        "    x: x value\n",
        "    I0: I0 value\n",
        "    a: a value\n",
        "    b: b value\n",
        "\n",
        "  Returns:\n",
        "    I0-a*exp(-b*x)\n",
        "  '''\n",
        "  return I0 - a * np.exp(-b * x)\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# Define the double exponential function\n",
        "def double_exponential_func(x, I0, a, b, c, d):\n",
        "  '''Double exponential function\n",
        "\n",
        "  Args:\n",
        "    x: x value\n",
        "    I0: I0 value\n",
        "    a: a value\n",
        "    b: b value\n",
        "    c: c value\n",
        "    d: d value\n",
        "\n",
        "  Returns:\n",
        "    I0-a*exp(-b*x)-c*exp(-d*x)\n",
        "  '''\n",
        "  return I0 - a * np.exp(-b * x) - c * np.exp(-d * x)\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# Define goodness of fitting\n",
        "def goodness_of_fit(y_data, fitted_y):\n",
        "  '''Computes goodness of fit using R-squared\n",
        "  Args:\n",
        "    y_data: original data\n",
        "    fitted_y: fitted data\n",
        "\n",
        "  Returns:\n",
        "    R-squared value\n",
        "  '''\n",
        "  ss_res = np.sum((y_data - fitted_y) ** 2)\n",
        "  ss_tot = np.sum((y_data - np.mean(y_data)) ** 2)\n",
        "  r_squared = 1 - (ss_res / ss_tot)\n",
        "  return r_squared\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "def find_x_at_half_max_double_exponential(x_data, I0, a, b, c, d):\n",
        "    \"\"\"\n",
        "    Finds the x-value where the double exponential function is at half its maximum.\n",
        "\n",
        "    Args:\n",
        "        x_data: Array of x-values.\n",
        "        I0, a, b, c, d: Parameters of the double exponential function.\n",
        "\n",
        "    Returns:\n",
        "        The x-value at half maximum, or None if no solution is found.\n",
        "    \"\"\"\n",
        "\n",
        "    y_max = I0\n",
        "    half_max = y_max / 2\n",
        "\n",
        "    # Define the function to solve for the root (where f(x) - half_max = 0)\n",
        "    def equation_to_solve(x):\n",
        "        return double_exponential_func(x, I0, a, b, c, d) - half_max\n",
        "\n",
        "    # Initial guess for x (you might need to adjust this based on your data)\n",
        "    initial_guess = x_data[np.argmin(np.abs(double_exponential_func(x_data, I0, a, b, c, d)-half_max))]\n",
        "\n",
        "    try:\n",
        "      x_half_max = fsolve(equation_to_solve, initial_guess)[0]\n",
        "      return x_half_max\n",
        "    except RuntimeError:\n",
        "      print(\"Error - fsolve failed to find a solution\")\n",
        "      return None\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "def fit_dataset_exponential(dataset_dir, dataset_name, is_single):\n",
        "  '''\n",
        "\n",
        "  Args:\n",
        "    dataset_dir: The directory containing the dataset.\n",
        "    dataset_name: The name of the dataset.\n",
        "    is_single: True if the fit should be performed based on a single exponential, otherwise will be performed on a double exponential.\n",
        "\n",
        "  Returns:\n",
        "    out_path: The path to the output directory.\n",
        "\n",
        "  '''\n",
        "  # Set fitting type attribute\n",
        "  fitting_type=\"_single-exponential\" if is_single else \"_double-exponential\"\n",
        "  fitting_type_legend=\"Single Exponential\" if is_single else \"Double Exponential\"\n",
        "\n",
        "  # Defines basename\n",
        "  basename=dataset_name.replace('_Quantif_Norm.xls', '')\n",
        "\n",
        "   # Open file\n",
        "  df = pd.read_csv(os.path.join(dataset_dir, dataset_name), sep='\\t')\n",
        "\n",
        "  # Create output dir\n",
        "  out_path=os.path.join(dataset_dir, basename)\n",
        "  if not os.path.exists(out_path):\n",
        "    os.mkdir(out_path)\n",
        "\n",
        "  # Select columns starting with \"Time_sec\" or \"Full_Scale\"\n",
        "  selected_columns = [col for col in df.columns if col.startswith('Time_sec') or col.startswith('MM_') or col.startswith('Full_Scale')]\n",
        "  new_df = df[selected_columns]\n",
        "\n",
        "  # Create lists to store fitted data and parameters\n",
        "  fitted_data = []\n",
        "  fitting_parameters = []\n",
        "  columns_names=['Time_sec']\n",
        "\n",
        "  with PdfPages(os.path.join(out_path, basename+fitting_type+'_plots.pdf')) as pdf:\n",
        "      for col in [col for col in new_df.columns if  col.startswith('MM_') or col.startswith('Full_Scale')]:\n",
        "          # Find the index of the largest drop\n",
        "          data = new_df[col].values\n",
        "          drop_indices = np.where(np.diff(data) < -50)[0]\n",
        "          if len(drop_indices) > 0:\n",
        "              max_drop_index = drop_indices[0]\n",
        "              x_data = new_df['Time_sec'][max_drop_index:]\n",
        "              y_data = new_df[col][max_drop_index:]\n",
        "\n",
        "              try:\n",
        "\n",
        "                  if(is_single):\n",
        "                    params, covariance = curve_fit(single_exponential_func, x_data, y_data, p0=[100, 90, 0.015])\n",
        "                    I0, a, b = params\n",
        "                    fitted_y = single_exponential_func(x_data, I0, a, b)\n",
        "                    #Extracted parameters\n",
        "                    t_half=np.log(2)/b\n",
        "                    mobile_fraction=100*a/(100-(I0-a)) # Used 100 instead of 1 cf normalisation between [0; 100] and not [0; 1]\n",
        "                  else:\n",
        "                    params, covariance = curve_fit(double_exponential_func, x_data, y_data, p0=[100, 60, 0.01, 30, 0.02])\n",
        "                    I0, a, b, c, d = params\n",
        "                    fitted_y = double_exponential_func(x_data, I0, a, b, c, d)\n",
        "                    #Extracted parameters\n",
        "                    t_half=find_x_at_half_max_double_exponential(x_data, I0, a, b, c, d)#find_x_at_half_max(x_data.to_numpy, fitted_y.to_numpy, I0)\n",
        "                    mobile_fraction=100*(a+c)/(100-(I0-a-c)) # Used 100 instead of 1 cf normalisation between [0; 100] and not [0; 1]\n",
        "\n",
        "                  # Get goodness of fitting\n",
        "                  r_squared = goodness_of_fit(y_data, fitted_y)\n",
        "\n",
        "\n",
        "\n",
        "                  columns_names.append(col)\n",
        "                  fitted_data.append(fitted_y)\n",
        "\n",
        "                  if(is_single):\n",
        "                    fitting_parameters.append([col, I0, a, b, r_squared, t_half, mobile_fraction])\n",
        "                  else:\n",
        "                    fitting_parameters.append([col, I0, a, b, c, d, r_squared, t_half, mobile_fraction])\n",
        "\n",
        "                  plt.figure(figsize=(10, 6))\n",
        "                  plt.plot(x_data, y_data, label='Data')\n",
        "                  plt.plot(x_data, fitted_y, label=fitting_type_legend+' Fit', color='red')\n",
        "                  plt.xlabel('Time_sec')\n",
        "                  plt.ylabel(col)\n",
        "                  plt.title(f'{col} vs. Time_sec ('+fitting_type_legend+' Fit)')\n",
        "                  plt.text(0.05, 0.95, f\"R-squared: {r_squared:.4f}\", transform=plt.gca().transAxes) #Display R-squared on the plot\n",
        "                  plt.legend()\n",
        "                  plt.grid(True)\n",
        "                  pdf.savefig()\n",
        "                  plt.close()\n",
        "\n",
        "              except RuntimeError:\n",
        "                  print(f\"Error - curve_fit failed for {col}\")\n",
        "                  fitting_parameters.append([col, \"Error\", \"Error\", \"Error\", \"Error\", np.nan, np.nan])\n",
        "          else:\n",
        "              print(f\"No significant drop found for {col}\")\n",
        "              fitting_parameters.append([col, \"No drop\", \"No drop\", \"No drop\", \"No drop\", np.nan, np.nan])\n",
        "\n",
        "  # Create and save Excel files\n",
        "  fitted_data_df = pd.DataFrame(fitted_data).T\n",
        "  fitted_data_df.insert(0, 't', new_df['Time_sec'])\n",
        "  fitted_data_df.columns = columns_names\n",
        "  fitted_data_df.to_excel(os.path.join(out_path, basename+fitting_type+'_fitted_values.xlsx'), index=False)\n",
        "\n",
        "  if(is_single):\n",
        "    fitting_parameters_df = pd.DataFrame(fitting_parameters, columns=['ROI', 'I0', 'a', 'b', 'R2', 't_half', 'mobile_fraction'])\n",
        "  else:\n",
        "    fitting_parameters_df = pd.DataFrame(fitting_parameters, columns=['ROI', 'I0', 'a', 'b', 'c', 'd', 'R2', 't_half', 'mobile_fraction'])\n",
        "\n",
        "  fitting_parameters_df.to_excel(os.path.join(out_path, basename+fitting_type+'_fitting_parameters.xlsx'), index=False)\n",
        "\n",
        "  return out_path\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "def unzip_file(zip_filepath, extract_dir):\n",
        "  \"\"\"Unzips a zip file to a specified directory.\n",
        "\n",
        "  Args:\n",
        "    zip_filepath: The path to the zip file.\n",
        "    extract_dir: The directory to extract the contents to.\n",
        "  \"\"\"\n",
        "  with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "def create_zip_from_folders(folder_list, zip_filename, remove_folder):\n",
        "  \"\"\"Creates a zip archive containing all folders from a given list.\n",
        "\n",
        "  Args:\n",
        "    folder_list: A list of folder paths to include in the zip archive.\n",
        "    zip_filename: The name of the output zip file.\n",
        "    remove_folder: True to erase the original folders after zipping.\n",
        "  \"\"\"\n",
        "  with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for folder in folder_list:\n",
        "      for root, _, files in os.walk(folder):\n",
        "        for file in files:\n",
        "          zipf.write(os.path.join(root, file),\n",
        "                     os.path.relpath(os.path.join(root, file),\n",
        "                                     os.path.join(folder, '..')))\n",
        "  if remove_folder:\n",
        "    for folder in folder_list:\n",
        "      shutil.rmtree(folder)\n",
        "\n"
      ],
      "metadata": {
        "id": "WuPksS0p8UFr",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Upload data\n",
        "_Simply execute the following cell, then select the file to upload_\n",
        "\n",
        "**NB:** This cell should be unfolded in order to see the file selection box !"
      ],
      "metadata": {
        "id": "45GNwQJGFBbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a dialog box to allow uploading the data\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "lFGhNvAbinLA",
        "outputId": "da41d92a-0842-4d3c-8f08-7422b9696a4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-40327463-7825-4f48-83af-c273a8a499ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-40327463-7825-4f48-83af-c273a8a499ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving _DataToUpload.zip to _DataToUpload.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Process data\n",
        "_Simply execute the following cell: once processing has been performed, the output file should automatically be downloaded to your computer_\n"
      ],
      "metadata": {
        "id": "yHXFZy0lFKBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the name of the (first) uploaded file\n",
        "uploaded_file=next(iter((uploaded)))\n",
        "\n",
        "# Build the full paths for uploaded and unzipped data\n",
        "uploaded_file_path=os.path.join('/content/', uploaded_file)\n",
        "unzip_folder=os.path.join('/content/', uploaded_file.replace('.zip', '/'))\n",
        "\n",
        "# Unzip the first file into the content folder\n",
        "unzip_file(uploaded_file_path, unzip_folder)\n",
        "\n",
        "# Remove uploaded file\n",
        "os.remove(uploaded_file)\n",
        "\n",
        "# Get the list of all the XLS files\n",
        "list_xls=list_xls_files(unzip_folder)\n",
        "created_folders=[]\n",
        "\n",
        "# Analyze data\n",
        "for xls in tqdm(list_xls, desc=\"Processing file\"):\n",
        "  tqdm.write(f\"Processing file: {os.path.basename(xls)}\")\n",
        "  created_folders.append(fit_dataset_exponential(unzip_folder, os.path.basename(xls), True))\n",
        "  fit_dataset_exponential(unzip_folder, os.path.basename(xls), False)\n",
        "\n",
        "# Zip the data\n",
        "create_zip_from_folders(created_folders, 'Fitted_data.zip', True)\n",
        "\n",
        "# Remove the data, once zipped\n",
        "shutil.rmtree(unzip_folder)\n",
        "\n",
        "# Automatically download the file\n",
        "files.download('Fitted_data.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YHXeJ6GYNijm",
        "outputId": "c23a7ffa-a7f1-449e-a5a6-11637d549541"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing file:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: 070525_A1-03_Quantif_Norm.xls\n",
            "Error - curve_fit failed for MM_Roi_3\n",
            "Error - curve_fit failed for MM_Roi_4\n",
            "Error - curve_fit failed for MM_Roi_5\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_3\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_4\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_5\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing file:  33%|███▎      | 1/3 [00:09<00:18,  9.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: 070525_A1-02_Quantif_Norm.xls\n",
            "Error - curve_fit failed for MM_Roi_3\n",
            "Error - curve_fit failed for MM_Roi_4\n",
            "Error - curve_fit failed for MM_Roi_5\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_3\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_4\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_5\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing file:  67%|██████▋   | 2/3 [00:18<00:09,  9.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: 070525_A1-01_Quantif_Norm.xls\n",
            "Error - curve_fit failed for MM_Roi_3\n",
            "Error - curve_fit failed for MM_Roi_4\n",
            "Error - curve_fit failed for MM_Roi_5\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_3\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_4\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_5\n",
            "Error - curve_fit failed for Full_Scale_MM_Roi_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing file: 100%|██████████| 3/3 [00:26<00:00,  8.72s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_514a1471-b71c-49db-ad41-2d1fbee0bd9b\", \"Fitted_data.zip\", 500625)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MN1zkTiDFUml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: What's in the output ?\n",
        "\n",
        "Once the script has finished processing the data, all outputs will be automatically zipped (Fitted_data.zip) and downloaded. It contains one folder per input dataset, named after the dataset. Each folder contains the following files:\n",
        "- **DATASET-NAME_single-exponential_plots.pdf:** for data where fitting against a single exponential was possible, displays one page per ROI, overlaying as a graph the fitted data to the original data.\n",
        "- **DATASET-NAME_single-exponential_fitted_values.xlsx:** for double normalized and full scale data, displays the modelized the values (when fitting a single exponential was possible).\n",
        "- **DATASET-NAME_single-exponential_fitting_parameters.xlsx:** for double normalized and full scale data, displays the parameters for the single exponential model, a goodness of fitting value and estimation of both the t_half and mobile fraction (when fitting was possible).\n",
        "- **DATASET-NAME_double-exponential_plots.pdf:** for data where fitting against a double exponential was possible, displays one page per ROI, overlaying as a graph the fitted data to the original data.\n",
        "- **DATASET-NAME_double-exponential_fitted_values.xlsx:** for double normalized and full scale data, displays the modelized the values (when fitting a double exponential was possible).\n",
        "- **DATASET-NAME_double-exponential_fitting_parameters.xlsx:** for double normalized and full scale data, displays the parameters for the double exponential model, a goodness of fitting value and estimation of both the t_half and mobile fraction (when fitting was possible)."
      ],
      "metadata": {
        "id": "uX1P_khYFVSf"
      }
    }
  ]
}